num_heads: 8            
num_layers: 6
embed_dim: 384         
ff_hidden_dim: 1536     
max_length: 256          
vocab_size: 50257
output_dim: 50257
qkv_bias: true
mha_dropout_rate: 0.1
ffn_dropout_rate: 0.1
emb_dropout_rate: 0.1
layer_norm_eps: 0.00001
learning_rate: 0.0005
weight_decay: 0.1
num_epochs: 20
eval_freq: 10
eval_iter: 5